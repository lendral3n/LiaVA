
=== Lip Sync Setup Flow in Unity (UniVRM + uLipSync) ===

1. Unity Hub
   - Click "New Project"
   - Select "3D (URP/Universal Render Pipeline)"
   - Name your project and click "Create"

2. Unity Editor
   - Open your new project
   - Import UniVRM:
     - Drag and drop the UniVRM .unitypackage into Unity
     - In the import window, click "Import All"

   - Import your .vrm file:
     - Drag and drop the .vrm file into Assets folder
     - It will auto-extract into a prefab in the scene

3. Add Audio for Lip Sync
   - Click on the VRM Avatar GameObject in the Hierarchy
   - Click "Add Component" -> Add:
     - "Audio Source"
     - "U Lip Sync"
   - In "Audio Source":
     - Set an AudioClip (MP3/WAV)
     - Check "Play On Awake" if needed
     - Check "Loop" if you want it to repeat

4. Link Audio Source to U Lip Sync
   - In the U Lip Sync component:
     - Drag your GameObject (that has the Audio Source) into the "Audio Source Proxy" field

5. (Optional) Live Mic Input
   - Instead of playing clip, you can add:
     - Component: "U Lip Sync Microphone"
     - Select your mic device from dropdown

6. Set BlendShape Profiles
   - In U Lip Sync, scroll to "Blend Shape Table"
   - Click "+" to add phoneme entries (e.g., A, I, U, E, O)
   - Assign corresponding BlendShape Clips from your VRM

7. Play Scene
   - Hit "Play" in Unity
   - Audio should play and drive mouth movement via blendshapes

Tips:
- Make sure AudioClip is not null
- Your VRM must contain proper blendshape (viseme) clips
- If TTS is used, load and assign the AudioClip at runtime
